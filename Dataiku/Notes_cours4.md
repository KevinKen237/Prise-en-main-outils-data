# ğŸ“š MLOps with Dataiku (MLOps avec Dataiku)

La formation **MLOps** dans Dataiku permet de transformer un modÃ¨le en un service opÃ©rationnel : construire un flow complet, exposer une API, la dÃ©ployer en production et automatiser le processus avec contrÃ´le qualitÃ© des donnÃ©es.  
Voici le rÃ©sumÃ© dÃ©taillÃ© des Ã©tapes suivies.

---

## ğŸ”§ Build the flow (Construire le flux)

- **Complete the flow for prediction**  
  ComplÃ©ter le *flow* afin dâ€™aller jusquâ€™Ã  la prÃ©diction.  
- **Build all the flow**  
  Construire lâ€™ensemble du flux (prÃ©paration, entraÃ®nement, scoring).

---

## ğŸŒ Create an API endpoint (CrÃ©er un point dâ€™accÃ¨s API)

- **Select the chosen model**  
  Choisir le modÃ¨le que lâ€™on souhaite exposer.  
- **Action â†’ Create API**  
  CrÃ©er une API Ã  partir du modÃ¨le.  
- **API service ID & Endpoint ID**  
  - API service ID : nom du dataset ou du projet (ex : `fake_jobs_service`)  
  - Endpoint ID : identifiant de lâ€™endpoint (ex : `predict_fake_job`)  
- **Test queries (5 minimum)**  
  - Ajouter des requÃªtes depuis le dataset de test  
  - Lancer les requÃªtes de test  
- **Inspect details**  
  VÃ©rifier :  
  - Les features envoyÃ©es Ã  lâ€™endpoint  
  - La prÃ©diction retournÃ©e  
  - Les dÃ©tails additionnels associÃ©s

---

## ğŸš€ Deploy an API endpoint (DÃ©ployer un point dâ€™accÃ¨s API)

- **Publish â†’ DÃ©ployer**  
  Publier le service API crÃ©Ã©.  
- **Open API Deployer**  
  - SÃ©lectionner *API Services*  
  - Rechercher lâ€™API service ID  
  - Cliquer sur *Deploy*  
  - Choisir une infrastructure disponible (ou en sÃ©lectionner une autre en cas dâ€™erreur)  
- **Warnings & Errors**  
  - Si *warning* : ignorer (liÃ© Ã  la *Govern Policy*)  
  - Si *error* : changer dâ€™infrastructure et relancer  
- **API endpoint in production**  
  Ã€ ce stade, lâ€™API est disponible dans un environnement de production.  
- **Run test queries**  
  - Depuis lâ€™Endpoint dans lâ€™API Deployer  
  - Naviguer vers *Run and Test Panel*  
  - Lancer toutes les requÃªtes (*Run all*)  

---

## ğŸ”„ Automate the Flow (Automatiser le flux)

- **Create a scenario**  
  - Onglet `|>` â†’ *Scenarios* â†’ sÃ©lectionner *score data*  
  - ParamÃ¨tres par dÃ©faut : exÃ©cution hebdomadaire (*weekly*)  
- **Configure build step**  
  - Naviguer dans *Steps*  
  - Cliquer sur *Build step* (cocher la case)  

---

## âœ… Check Data Quality (VÃ©rifier la qualitÃ© des donnÃ©es)

### DÃ©finir une rÃ¨gle qualitÃ©
- Dans la zone *Data Preparation Flow*, ouvrir le dataset prÃ©parÃ©  
- Onglet *Data Quality* â†’ *Edit Rules*  
- Ajouter la rÃ¨gle *Record count in range*  
- Configurer et tester la rÃ¨gle

### IntÃ©grer la rÃ¨gle dans un scÃ©nario
- Ouvrir `|>` â†’ *Scenarios* â†’ sÃ©lectionner *score data*  
- Aller dans *Steps* â†’ *Add step* â†’ *Verify rules or run checks*  
- Cliquer sur *+ Add item* â†’ *Dataset* â†’ sÃ©lectionner `prepared_dataset` â†’ *Add*  
- Glisser cette Ã©tape tout en haut (drag avec `::`)  
- Lancer le scÃ©nario (*Run*) pour tester lâ€™exÃ©cution  

### Inspecter le rÃ©sultat
- Onglet *Last runs* du scÃ©nario â†’ consulter le dernier run  
- Ouvrir le *Build step* â†’ constater que rien nâ€™est exÃ©cutÃ© si la rÃ¨gle nâ€™est pas satisfaite  

---

ğŸ‘‰ Avec ce workflow complet, Dataiku permet de :  
1. CrÃ©er un modÃ¨le prÃ©dictif prÃªt pour la production  
2. Lâ€™exposer en tant quâ€™API et le dÃ©ployer  
3. Automatiser les exÃ©cutions via scÃ©narios  
4. Garantir la qualitÃ© des donnÃ©es avant toute tÃ¢che  

Un vÃ©ritable processus **MLOps intÃ©grÃ© et opÃ©rationnel**.
e, Dataiku rend le **MLOps accessible et opÃ©rationnel** : dÃ©ployer un modÃ¨le, lâ€™exposer en API, automatiser les mises Ã  jour et garantir la qualitÃ© des donnÃ©es deviennent des Ã©tapes intÃ©grÃ©es et simples Ã  suivre.
